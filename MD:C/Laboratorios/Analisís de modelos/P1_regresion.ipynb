{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moisestellezfrancisco/.local/lib/python3.10/site-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Density   Age  Weight  Height  Neck  Chest  Abdomen    Hip  Thigh  Knee  \\\n",
      "0   1.0708  23.0  154.25   67.75  36.2   93.1     85.2   94.5   59.0  37.3   \n",
      "1   1.0853  22.0  173.25   72.25  38.5   93.6     83.0   98.7   58.7  37.3   \n",
      "2   1.0414  22.0  154.00   66.25  34.0   95.8     87.9   99.2   59.6  38.9   \n",
      "3   1.0751  26.0  184.75   72.25  37.4  101.8     86.4  101.2   60.1  37.3   \n",
      "4   1.0340  24.0  184.25   71.25  34.4   97.3    100.0  101.9   63.2  42.2   \n",
      "\n",
      "   Ankle  Biceps  Forearm  Wrist  \n",
      "0   21.9    32.0     27.4   17.1  \n",
      "1   23.4    30.5     28.9   18.2  \n",
      "2   24.0    28.8     25.2   16.6  \n",
      "3   22.8    32.4     29.4   18.2  \n",
      "4   24.0    32.2     27.7   17.7  \n",
      "(252, 14)\n",
      "0    12.3\n",
      "1     6.1\n",
      "2    25.3\n",
      "3    10.4\n",
      "4    28.7\n",
      "Name: target, dtype: float64\n",
      "(252,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn import linear_model as lm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bodyfat = fetch_openml(name='bodyfat', version=1)\n",
    "df = pd.DataFrame(data= np.c_[bodyfat['data'], bodyfat['target']],\n",
    "                     columns= bodyfat['feature_names'] + ['target'])\n",
    "y = df['target']\n",
    "X = df.loc[:, df.columns != 'target']\n",
    "print(X.head())\n",
    "print(X.shape)\n",
    "print(y.head())\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  1.5272035183907957\n",
      "Mean absolute error:  0.4801966008373651\n",
      "R2 score:  0.9781070874885561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression().fit(X, y)\n",
    "\n",
    "y_pred = reg.predict(X)\n",
    "print(\"Mean squared error: \", mean_squared_error(y, y_pred))\n",
    "print(\"Mean absolute error: \", mean_absolute_error(y, y_pred))\n",
    "print(\"R2 score: \", r2_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "\n",
    "Selecciona un par de variables interesantes para poder dibujar el gráfico de la regresión lineal y observa el ajuste gráfico frente a las medidas de rendimiento obtenidas\n",
    "\n",
    "Para dibujar un gráfico de ajuste con scatter plot puedes usar este código básico:\n",
    "```python\n",
    "plt.scatter(X, y,color='g') \n",
    "plt.plot(X, y_pred, color='k') \n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1.0708\n",
       "1      1.0853\n",
       "2      1.0414\n",
       "3      1.0751\n",
       "4      1.0340\n",
       "        ...  \n",
       "247    1.0736\n",
       "248    1.0236\n",
       "249    1.0328\n",
       "250    1.0399\n",
       "251    1.0271\n",
       "Name: Density, Length: 252, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Density']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df['target']\n",
    "X = np.array(df['Density']).reshape(-1,1)\n",
    "\n",
    "reg = LinearRegression().fit(X, y)\n",
    "\n",
    "y_pred = reg.predict(X)\n",
    "plt.scatter(X, y,color='g') \n",
    "plt.plot(X, y_pred, color='k') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión polinomial\n",
    "\n",
    "En Scikit Learn, la regresión polinomial se crea aplicando una transformación a los atributos, generando los nuevos atributos con los coeficientes del polinomio. A continuación, se realiza un ajuste de una regresión lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  1.3409751178113556\n",
      "Mean absolute error:  0.3451359839261892\n",
      "R2 score:  0.9807767264934006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Por defecto, PolynomialFeatures incluye el término independiente Bias a true\n",
    "poly_reg = PolynomialFeatures(degree=3) #cuidado con el grado: el número de coeficientes crece exponencialmente con su valor de acuerdo a la matriz de Vandermonde\n",
    "\n",
    "X_poly = poly_reg.fit_transform(X)\n",
    "\n",
    "# Ya tenemos las características transformadas, ahora entrenamos el modelo\n",
    "reg2 = LinearRegression()\n",
    "reg2.fit(X_poly,y) # Aquí es donde ajustamos los coefientes del modelo y reg2 se actualiza en consecuencia\n",
    "\n",
    "y_pred = reg2.predict(X_poly)\n",
    "\n",
    "print(\"Mean squared error: \", mean_squared_error(y, y_pred))\n",
    "print(\"Mean absolute error: \", mean_absolute_error(y, y_pred))\n",
    "print(\"R2 score: \", r2_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible crear un flujo completo de trabajo utilizando la función make_pipeline().\n",
    "\n",
    "Esta función genera la transformación y la aplica al regresor (lineal en nuestro caso) en una única línea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  1.2821633691193657\n",
      "Mean absolute error:  0.28647076705810687\n",
      "R2 score:  0.9816198102430475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "reg3 = make_pipeline(PolynomialFeatures(degree=5), LinearRegression())\n",
    "reg3.fit(X,y) \n",
    "\n",
    "y_pred = reg3.predict(X) # Fíjate que utilizamos los datos sin transformar para realizar la predicción. El pipeline se encarga de realizar la transformación\n",
    "\n",
    "print(\"Mean squared error: \", mean_squared_error(y, y_pred))\n",
    "print(\"Mean absolute error: \", mean_absolute_error(y, y_pred))\n",
    "print(\"R2 score: \", r2_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "¿Por qué los valores de rendimiento mejoran cuando aumentamos el grado del ajuste polinomial? Pruebe a realizar una validación de training y test (mínimo un Hold-out) y observe de nuevo el efecto de aumentar el grado del polinomio.\n",
    "\n",
    "**Nota**: Si utiliza particiones de entrenamiento y test, tendrá que aplicar el método fit_transform a los valores X tanto del conjunto de entrenamiento como del conjunto de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión con Splines\n",
    "\n",
    "En la regresión con splines se aplica la regresión polinómica \"a trozos\": entre ciertos valores de los atributos de entrada (los nodos o \"knots\") se genera el ajuste de un regresor polinómico.\n",
    "Esto supone crear una transformación como la que hemos visto para la regresión polinómica, pero la matriz de transformación es diferente ahora.\n",
    "\n",
    "Además, hemos de elegir qué estimador polinómico queremos ajustar entre los nodos.\n",
    "\n",
    "Para condensar el ejemplo, utilizaremos la función make_pipeline() de nuevo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  0.19489839254863678\n",
      "Mean absolute error:  0.23933105468749996\n",
      "R2 score:  0.9972060741051826\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, SplineTransformer\n",
    "\n",
    "spline = make_pipeline(SplineTransformer(n_knots=8, degree=6), LinearRegression()) #n_knots es el número de puntos de control y degree el grado del polinomio\n",
    "spline.fit(X, y)\n",
    "\n",
    "y_pred = spline.predict(X)\n",
    "\n",
    "print(\"Mean squared error: \", mean_squared_error(y, y_pred))\n",
    "print(\"Mean absolute error: \", mean_absolute_error(y, y_pred))\n",
    "print(\"R2 score: \", r2_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "\n",
    "1. Observa el efecto del número de nodos o puntos de control y del grado en el rendimiento del algoritmo.\n",
    "2. Experimenta con una validación adecuada (Hold-out o validación cruzada) y el uso del pipeline para realizar la validación.\n",
    "3. Prueba a elegir un atributo de entrada para poder pintar con un plot el resultado del ajuste spline frente a la salida.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión lineal a trozos (LOESS)\n",
    "\n",
    "Actualmente, sklearn no incluye este modelo de regresión, aunque el paquete statmodels sí incluye una versión unidimensional.\n",
    "\n",
    "La incluimos a continuación y mostramos un ejemplo de su utilización en nuestro conjunto para una de las características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  21.279077149942545\n",
      "Mean absolute error:  3.716767301273681\n",
      "R2 score:  0.694958157994011\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from statsmodels.api import nonparametric\n",
    "\n",
    "X_mono = X['Abdomen'] # La regresión linea a trozos sólo admite una variable independiente en statsmodels\n",
    "\n",
    "\n",
    "lowess_sm = nonparametric.lowess\n",
    "\n",
    "y_pred = lowess_sm(y,X_mono.to_numpy(),frac=1./3.,it=3, return_sorted = False)\n",
    "print(\"Mean squared error: \", mean_squared_error(y, y_pred))\n",
    "print(\"Mean absolute error: \", mean_absolute_error(y, y_pred))\n",
    "print(\"R2 score: \", r2_score(y, y_pred))\n",
    "\n",
    "plt.scatter(X['Abdomen'], y, color = 'red')\n",
    "plt.plot(X['Abdomen'], y_pred, color = 'blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "\n",
    "Se aprecia como la regresión \"va y vuelve\". Intente solucionarlo ordenando los datos de entrada (X_mono)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Additive Models\n",
    "\n",
    "De nuevo, sklearn no tiene una implementación nativa de GAMs. Es posible encontrar una buena biblioteca en https://pygam.readthedocs.io/en/latest/\n",
    "\n",
    "La información para su instalación está en https://pygam.readthedocs.io/en/latest/notebooks/quick_start.html#Install-pyGAM\n",
    "\n",
    "Recordemos que las GAMs permiten establecer linealidades o no linealidades en diferentes atributos a nuestra elección. PyGAM especifica esto en la creación del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearGAM                                                                                                 \n",
      "=============================================== ==========================================================\n",
      "Distribution:                        NormalDist Effective DoF:                                     92.6098\n",
      "Link Function:                     IdentityLink Log Likelihood:                                  -334.9558\n",
      "Number of Samples:                          252 AIC:                                              857.1311\n",
      "                                                AICc:                                             969.6719\n",
      "                                                GCV:                                                3.0667\n",
      "                                                Scale:                                              1.1429\n",
      "                                                Pseudo R-Squared:                                   0.9896\n",
      "==========================================================================================================\n",
      "Feature Function                  Lambda               Rank         EDoF         P > x        Sig. Code   \n",
      "================================= ==================== ============ ============ ============ ============\n",
      "s(0)                              [0.6]                20           13.9         1.11e-16     ***         \n",
      "s(1)                              [0.6]                20           12.9         6.27e-02     .           \n",
      "f(2)                              [0.6]                197          65.0         1.53e-01                 \n",
      "l(3)                              [0.6]                1            0.1          2.88e-01                 \n",
      "l(4)                              [0.6]                1            0.1          8.60e-01                 \n",
      "l(5)                              [0.6]                1            0.1          7.32e-02     .           \n",
      "l(6)                              [0.6]                1            0.1          3.31e-01                 \n",
      "l(7)                              [0.6]                1            0.1          8.00e-01                 \n",
      "l(8)                              [0.6]                1            0.1          4.46e-02     *           \n",
      "l(9)                              [0.6]                1            0.1          8.58e-01                 \n",
      "l(10)                             [0.6]                1            0.1          2.93e-01                 \n",
      "l(11)                             [0.6]                1            0.0          7.71e-01                 \n",
      "l(12)                             [0.6]                1            0.0          4.83e-01                 \n",
      "l(13)                             [0.6]                1            0.0          8.77e-01                 \n",
      "intercept                                              1            0.0          8.34e-14     ***         \n",
      "==========================================================================================================\n",
      "Significance codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
      "\n",
      "WARNING: Fitting splines and a linear function to a feature introduces a model identifiability problem\n",
      "         which can cause p-values to appear significant when they are not.\n",
      "\n",
      "WARNING: p-values calculated in this manner behave correctly for un-penalized models or models with\n",
      "         known smoothing parameters, but when smoothing parameters have been estimated, the p-values\n",
      "         are typically lower than they should be, meaning that the tests reject the null too readily.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julian\\AppData\\Local\\Temp\\ipykernel_37504\\3414484672.py:14: UserWarning: KNOWN BUG: p-values computed in this summary are likely much smaller than they should be. \n",
      " \n",
      "Please do not make inferences based on these values! \n",
      "\n",
      "Collaborate on a solution, and stay up to date at: \n",
      "github.com/dswah/pyGAM/issues/163 \n",
      "\n",
      "  gam.summary()\n"
     ]
    }
   ],
   "source": [
    "from pygam import LinearGAM, s, f, l\n",
    "\n",
    "# Definimos el modelo utilizando las siguientes funciones:\n",
    "# 1. la función s para indicar que se ajustara una función spline a la variable independiente con el correspondiente índice\n",
    "# 2. En el caso de usar f, se aplicará un factor de ajuste a la variable independiente con el correspondiente índice\n",
    "# 3. En el caso de usar l, se aplicará un término lineal a la variable independiente con el correspondiente índice\n",
    "\n",
    "# Tenemos 14 atributos de entrada en nuestro conjunto, vamos a realizar un ajuste por cada uno de ellos de forma arbitraria\n",
    "gam = LinearGAM(s(0) + s(1) + f(2) + l(3) + l(4) + l(5) + l(6) + l(7) + l(8) + l(9) + l(10) + l(11) + l(12) + l(13))\n",
    "\n",
    "gam.fit(X, y)\n",
    "\n",
    "#Vamos a visualizar el modelo\n",
    "gam.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  0.7228584994869833\n",
      "Mean absolute error:  0.38610795714579593\n",
      "R2 score:  0.9896376103794619\n"
     ]
    }
   ],
   "source": [
    "y_pred = gam.predict(X)\n",
    "\n",
    "print(\"Mean squared error: \", mean_squared_error(y, y_pred))\n",
    "print(\"Mean absolute error: \", mean_absolute_error(y, y_pred))\n",
    "print(\"R2 score: \", r2_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "1. Observe los p-values devueltos por el summary() de nuestra GAM. Aquellos valores más bajos dan pistas de los atributos más importantes. Prueve a variar el ajuste utilizado para esos atributos.\n",
    "2. Pruebe a ajustar los parámetros de regularización con el método gridsearch() (más info en https://pygam.readthedocs.io/en/latest/notebooks/quick_start.html#Automatically-tune-the-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradiente descendente estocástico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  4.980196662455605e+28\n",
      "Mean absolute error:  221866626764848.4\n",
      "R2 score:  -7.139258684776369e+26\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sgd = SGDRegressor(max_iter=1000, tol=1e-3, penalty='l2', alpha=0.1, eta0=0.01, learning_rate='constant', loss='squared_error', random_state=100)\n",
    "sgd.fit(X, y)\n",
    "\n",
    "y_pred = sgd.predict(X)\n",
    "\n",
    "print(\"Mean squared error: \", mean_squared_error(y, y_pred))\n",
    "print(\"Mean absolute error: \", mean_absolute_error(y, y_pred))\n",
    "print(\"R2 score: \", r2_score(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados obtenidos en el bloque de código anterior son muy pobres.\n",
    "\n",
    "Vamos a normalizar los datos para que tengan media 0 y desviación típica 1, ya que el uso de **SGD** sin normalizar los datos puede provocar que el modelo no converja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  2.263134801441148\n",
      "Mean absolute error:  1.026306982309168\n",
      "R2 score:  0.9675572956630156\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scal = scaler.fit_transform(X)\n",
    "sgd.fit(X_scal, y)\n",
    "\n",
    "y_pred = sgd.predict(X_scal)\n",
    "\n",
    "print(\"Mean squared error: \", mean_squared_error(y, y_pred))\n",
    "print(\"Mean absolute error: \", mean_absolute_error(y, y_pred))\n",
    "print(\"R2 score: \", r2_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "1. Pruebe diferentes parámetros max_iter, tol, alpha y eta  de SGDRegressor y observe el comportamiento del regresor.\n",
    "2. Es muy habitual realizar el escalado y el fit() del SGDRegressor. SKlearn proporciona un pipeline para juntar las dos tareas. Examine la documentación de https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html y aplique el método make_pipeline al ejemplo anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  16.085521192268327\n",
      "Mean absolute error:  3.298424337773154\n",
      "R2 score:  0.7694093132168961\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "ridge = linear_model.Ridge(alpha=.5)\n",
    "ridge.fit(X, y)\n",
    "\n",
    "y_pred = ridge.predict(X)\n",
    "\n",
    "print(\"Mean squared error: \", mean_squared_error(y, y_pred))\n",
    "print(\"Mean absolute error: \", mean_absolute_error(y, y_pred))\n",
    "print(\"R2 score: \", r2_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "1. Intente obtener el mismo comportamiento que el regresor lineal con el Ridge regressor\n",
    "2. De igual forma, es posible emular el comportamiento del Ridge regressor mediante el regresor SGD. Revise las transparencias de teoría e intente obtener dicha equivalencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  18.782909101274438\n",
      "Mean absolute error:  3.537901971107\n",
      "R2 score:  0.7307414626061788\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "lasso = linear_model.Lasso(alpha=.5)\n",
    "lasso.fit(X, y)\n",
    "\n",
    "y_pred = lasso.predict(X)\n",
    "\n",
    "print(\"Mean squared error: \", mean_squared_error(y, y_pred))\n",
    "print(\"Mean absolute error: \", mean_absolute_error(y, y_pred))\n",
    "print(\"R2 score: \", r2_score(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "1. Tal y como ocurría con el Ridge regressor, puede emular el comportamiento del Ridge regressor mediante el regresor SGD. Revise las transparencias de teoría e intente obtener dicha equivalencia.\n",
    "2. Observe los coeficientes del ajuste del regresor Lasso con el método **.coef_** e identifique los atributos menos importantes.\n",
    "3. Con la información del punto 2, podría eliminar los atributos con un peso de cero del conjunto y mejorar el rendimiento (velocidad) de ajuste del modelo sin afectar apenas al rendimiento. Pruébelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  18.13871712209908\n",
      "Mean absolute error:  3.477151372336551\n",
      "R2 score:  0.7399761444745917\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "elastic = linear_model.ElasticNet(alpha=0.5, l1_ratio=0.5)\n",
    "elastic.fit(X, y)\n",
    "\n",
    "y_pred = elastic.predict(X)\n",
    "\n",
    "print(\"Mean squared error: \", mean_squared_error(y, y_pred))\n",
    "print(\"Mean absolute error: \", mean_absolute_error(y, y_pred))\n",
    "print(\"R2 score: \", r2_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "1. Dado que Elastic Net es una \"combinación\" de Lasso y Ridge, pruebe a modificar el parámetro **l1_ratio** para emular el comportamiento obtenido en los dos modelos mencionados.\n",
    "2. Observe también como cambian los coeficientes del ajuste de Elastic Net cuando modifica el **l1_ratio**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión mediante mínimos cuadrados parciales (PLS regression)\n",
    "\n",
    "En https://scikit-learn.org/stable/modules/cross_decomposition.html es posible leer las diferentes versiones de este algoritmo. El algoritmo base es PLSCanonical, y el resto de versiones realizan modificaciones al algoritmo base para ganar eficiencia o aplicar regularizaciones.\n",
    "\n",
    "A diferencia de lo visto en teoría, no vamos a realizar la regresión de PCA+Linear regression y nos centraremos en PLS directamente. Esperaremos a la práctica de preprocesamiento para aprender cómo aplicar PCA en nuestros datos. En cualquier caso, si tienes curiosidad, este tema está tratado en sklearn directamente: https://scikit-learn.org/stable/auto_examples/cross_decomposition/plot_pcr_vs_pls.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLS Canonical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  301.6937867138695\n",
      "Mean absolute error:  13.576250276918342\n",
      "R2 score:  -3.324869343368551\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSCanonical\n",
    "\n",
    "#n_components es el número de componentes principales a utilizar\n",
    "pls = PLSCanonical(n_components=1, tol= 0.001, max_iter=5000) \n",
    "pls.fit(X, y)\n",
    "\n",
    "y_pred = pls.predict(X)\n",
    "\n",
    "print(\"Mean squared error: \", mean_squared_error(y, y_pred))\n",
    "print(\"Mean absolute error: \", mean_absolute_error(y, y_pred))\n",
    "print(\"R2 score: \", r2_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLS regression\n",
    "\n",
    "Permite hacer regresión de una variable (PLS1 con n_components=1) o varios (PLS2 con n_components > 1).\n",
    "A diferencia de PLSCanonical, el número de componentes no está limitado por el número de atributos de salida. Se encuentra en el mínimo de $[1, min(\\#atributos, \\#ejemplos)]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  8.328809619946012\n",
      "Mean absolute error:  2.2654707764796984\n",
      "R2 score:  0.880604059551878\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "#n_components es el número de componentes principales a utilizar\n",
    "#prueba a aumentar el número de componentes y observa como cambia el error\n",
    "pls = PLSRegression(n_components=2, tol= 0.001, max_iter=5000) \n",
    "pls.fit(X, y)\n",
    "\n",
    "y_pred = pls.predict(X)\n",
    "\n",
    "print(\"Mean squared error: \", mean_squared_error(y, y_pred))\n",
    "print(\"Mean absolute error: \", mean_absolute_error(y, y_pred))\n",
    "print(\"R2 score: \", r2_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "1. Con la experiencia de estos dos métodos, prueba a ajustar con PLSSVD los datos: https://scikit-learn.org/stable/modules/generated/sklearn.cross_decomposition.PLSSVD.html#sklearn.cross_decomposition.PLSSVD\n",
    "2. ¿Cuál es el efecto del número de componentes en PLSRegression en el rendimiento? ¿Hay alguna asíntota de rendimiento? \n",
    "3. ¿Qué ocurre con los coeficientes al aumentar el número de componentes?\n",
    "4. Prueba a aplicar algún tipo de estandarízación en los datos y observa las diferencias en rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión con MLP (Multi-layer Perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP de SKlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 680.09453479\n",
      "Iteration 2, loss = 270.82359745\n",
      "Iteration 3, loss = 199.98164983\n",
      "Iteration 4, loss = 190.55066669\n",
      "Iteration 5, loss = 178.70264099\n",
      "Iteration 6, loss = 163.41529596\n",
      "Iteration 7, loss = 143.65324612\n",
      "Iteration 8, loss = 119.59976569\n",
      "Iteration 9, loss = 93.03300673\n",
      "Iteration 10, loss = 67.47757320\n",
      "Iteration 11, loss = 46.92496448\n",
      "Iteration 12, loss = 36.45189176\n",
      "Iteration 13, loss = 35.78870571\n",
      "Iteration 14, loss = 40.65504252\n",
      "Iteration 15, loss = 45.12825288\n",
      "Iteration 16, loss = 45.79304255\n",
      "Iteration 17, loss = 42.92700037\n",
      "Iteration 18, loss = 39.38271242\n",
      "Iteration 19, loss = 36.50136592\n",
      "Iteration 20, loss = 35.18741262\n",
      "Iteration 21, loss = 34.85291575\n",
      "Iteration 22, loss = 35.17938944\n",
      "Iteration 23, loss = 35.55177131\n",
      "Iteration 24, loss = 35.84514861\n",
      "Iteration 25, loss = 35.83443102\n",
      "Iteration 26, loss = 35.67468121\n",
      "Iteration 27, loss = 35.40266195\n",
      "Iteration 28, loss = 35.19107489\n",
      "Iteration 29, loss = 34.94287865\n",
      "Iteration 30, loss = 34.88584148\n",
      "Iteration 31, loss = 34.89394710\n",
      "Iteration 32, loss = 34.98919233\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean squared error:  69.92776595830891\n",
      "Mean absolute error:  6.865490357056632\n",
      "R2 score:  -0.0024351331112046903\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(10,10), activation='relu', solver='sgd', learning_rate='constant', max_iter=500, verbose=True, random_state=100)\n",
    "mlp.fit(X, y)\n",
    "\n",
    "y_pred = mlp.predict(X)\n",
    "\n",
    "print(\"Mean squared error: \", mean_squared_error(y, y_pred))\n",
    "print(\"Mean absolute error: \", mean_absolute_error(y, y_pred))\n",
    "print(\"R2 score: \", r2_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "1. Cambia la topología de la red (la cantidad de capas ocultas y el número de neuronas) para intentar mejorar los resultados\n",
    "2. Puedes ajustar el resto de parámetros (info en https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html) para intentar conseguir mejorar los resultados.\n",
    "3. Juega con el **learning_rate** frente al número de iteraciones y los resultados. Cambiar el **solver** también tiene un impacto importante en la velocidad de convergencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP con Keras\n",
    "\n",
    "Aunque en asignaturas más avanzadas se trabajará con Keras de forma más profunda, aprovechamos aquí para hacer un pequeño inciso.\n",
    "\n",
    "En Keras, la construcción de la topología de la red para obtener una MLP se hace artesanalmente, añadiendo capas de izquierda a derecha (utilizando un modelo Sequential), comenzando por la primera capa de conexión con los atributos del dataset y terminando con la última neurona de salida.\n",
    "\n",
    "Para facilitar la tarea vamos a utilizar un wrapper que incorpora Sklearn para trabajar con Keras de la misma forma que hemos hecho con los algoritmos de regresión previos. Queda como tarea al alumno replicar el uso de Keras directamente mostrado en las transparencias de teoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikeras in c:\\users\\julian\\anaconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: packaging>=0.21 in c:\\users\\julian\\anaconda3\\lib\\site-packages (from scikeras) (21.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\julian\\anaconda3\\lib\\site-packages (from scikeras) (1.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\julian\\anaconda3\\lib\\site-packages (from packaging>=0.21->scikeras) (3.0.9)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\julian\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\julian\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\julian\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\julian\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\n#Alternativamente, podemos definir la topología del modelo MLP como un vector de capas directamente en lugar de usar el método add\\nmlp = models.Sequential(\\n    [\\n        keras.layers.Dense(10, activation=\"relu\", input_shape=(X.shape[1],)),\\n        keras.layers.Dense(10, activation=\"relu\"),\\n        keras.layers.Dense(1)\\n    ]\\n)\\nmlp.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mse\"])\\n\\nmlp.summary()\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "#vamos a definir la topología del modelo MLP igual al ejemplo con MLPRegressor (2 capas ocultas de 10 neuronas cada una)\n",
    "def mlp():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=len(X.columns), activation='relu')) #capa de entrada con input_dim = número de atributos de nuestro conjunto de datos\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse']) #para regresión usamos mean_squared_error como función de pérdida\n",
    "    return model\n",
    "\n",
    "\"\"\"\"\n",
    "#Alternativamente, podemos definir la topología del modelo MLP como un vector de capas directamente en lugar de usar el método add\n",
    "mlp = models.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(10, activation=\"relu\", input_shape=len(X.columns)),\n",
    "        keras.layers.Dense(10, activation=\"relu\"),\n",
    "        keras.layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "mlp.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "mlp.summary()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 756.1449 - mse: 756.1449\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 50.3944 - mse: 50.3944\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 46.1248 - mse: 46.1248\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 972us/step - loss: 45.9141 - mse: 45.9141\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 982us/step - loss: 44.8329 - mse: 44.8329\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 973us/step - loss: 43.5094 - mse: 43.5094\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 990us/step - loss: 42.5344 - mse: 42.5344\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 975us/step - loss: 42.2742 - mse: 42.2742\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 972us/step - loss: 42.9078 - mse: 42.9078\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 972us/step - loss: 42.1032 - mse: 42.1032\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 41.2977 - mse: 41.2977\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 923us/step - loss: 40.2437 - mse: 40.2437\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 40.6971 - mse: 40.6971\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 39.0654 - mse: 39.0654\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 963us/step - loss: 38.5889 - mse: 38.5889\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 992us/step - loss: 38.4621 - mse: 38.4621\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 992us/step - loss: 38.0755 - mse: 38.0755\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 972us/step - loss: 37.4995 - mse: 37.4995\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 37.9048 - mse: 37.9048\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 37.7249 - mse: 37.7249\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 35.7391 - mse: 35.7391\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 34.7546 - mse: 34.7546\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 903us/step - loss: 34.7900 - mse: 34.7900\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 794us/step - loss: 34.4148 - mse: 34.4148\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 903us/step - loss: 33.3901 - mse: 33.3901\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 864us/step - loss: 34.6542 - mse: 34.6542\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 873us/step - loss: 31.7817 - mse: 31.7817\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 913us/step - loss: 34.3055 - mse: 34.3055\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 863us/step - loss: 31.6685 - mse: 31.6685\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 863us/step - loss: 32.4857 - mse: 32.4857\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 29.9772 - mse: 29.9772\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 863us/step - loss: 31.7762 - mse: 31.7762\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 928us/step - loss: 30.3613 - mse: 30.3613\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 32.2902 - mse: 32.2902\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 29.6550 - mse: 29.6550\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 973us/step - loss: 30.4203 - mse: 30.4203\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 883us/step - loss: 28.4312 - mse: 28.4312\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 873us/step - loss: 28.1145 - mse: 28.1145\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 913us/step - loss: 28.0197 - mse: 28.0197\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 848us/step - loss: 27.7440 - mse: 27.7440\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 863us/step - loss: 27.1198 - mse: 27.1198\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 833us/step - loss: 26.5206 - mse: 26.5206\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 824us/step - loss: 26.1845 - mse: 26.1845\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 893us/step - loss: 25.7628 - mse: 25.7628\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 913us/step - loss: 25.3374 - mse: 25.3374\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 933us/step - loss: 26.0170 - mse: 26.0170\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 952us/step - loss: 24.7308 - mse: 24.7308\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 903us/step - loss: 25.8223 - mse: 25.8223\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 973us/step - loss: 24.1833 - mse: 24.1833\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 903us/step - loss: 24.5988 - mse: 24.5988\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 933us/step - loss: 23.7679 - mse: 23.7680\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 903us/step - loss: 23.7819 - mse: 23.7819\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 932us/step - loss: 24.7265 - mse: 24.7265\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 853us/step - loss: 23.2750 - mse: 23.2750\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 877us/step - loss: 23.8283 - mse: 23.8283\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 853us/step - loss: 23.0832 - mse: 23.0832\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 942us/step - loss: 23.0970 - mse: 23.0970\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 24.5159 - mse: 24.5159\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 873us/step - loss: 22.9297 - mse: 22.9297\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 952us/step - loss: 22.8065 - mse: 22.8065\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 23.1683 - mse: 23.1683\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 833us/step - loss: 24.1524 - mse: 24.1524\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 923us/step - loss: 22.6839 - mse: 22.6839\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 883us/step - loss: 22.5439 - mse: 22.5439\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 883us/step - loss: 22.7249 - mse: 22.7249\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 844us/step - loss: 22.0989 - mse: 22.0989\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 943us/step - loss: 23.6005 - mse: 23.6005\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 873us/step - loss: 23.8285 - mse: 23.8285\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 873us/step - loss: 22.5006 - mse: 22.5006\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 913us/step - loss: 22.4680 - mse: 22.4680\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 932us/step - loss: 22.3828 - mse: 22.3828\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 883us/step - loss: 24.1697 - mse: 24.1697\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 863us/step - loss: 21.8284 - mse: 21.8284\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 952us/step - loss: 22.5447 - mse: 22.5447\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 883us/step - loss: 21.3448 - mse: 21.3448\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 872us/step - loss: 25.7010 - mse: 25.7010\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 883us/step - loss: 23.3974 - mse: 23.3974\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 923us/step - loss: 21.6109 - mse: 21.6109\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 923us/step - loss: 22.5658 - mse: 22.5658\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 923us/step - loss: 21.6542 - mse: 21.6542\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 22.3329 - mse: 22.3329\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 913us/step - loss: 22.1318 - mse: 22.1318\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 972us/step - loss: 22.7125 - mse: 22.7125\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 982us/step - loss: 22.0944 - mse: 22.0944\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 24.1373 - mse: 24.1373\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 903us/step - loss: 20.7961 - mse: 20.7961\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 833us/step - loss: 22.8720 - mse: 22.8720\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 853us/step - loss: 21.2853 - mse: 21.2853\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 843us/step - loss: 22.5822 - mse: 22.5822\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 834us/step - loss: 21.8303 - mse: 21.8303\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 874us/step - loss: 21.7852 - mse: 21.7852\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 903us/step - loss: 22.0260 - mse: 22.0260\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 843us/step - loss: 20.3895 - mse: 20.3895\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 913us/step - loss: 22.6894 - mse: 22.6894\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 942us/step - loss: 21.9559 - mse: 21.9559\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 913us/step - loss: 21.5543 - mse: 21.5543\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 923us/step - loss: 20.9887 - mse: 20.9887\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 20.2233 - mse: 20.2233\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 20.5091 - mse: 20.5091\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 20.5583 - mse: 20.5583\n",
      "51/51 [==============================] - 0s 803us/step\n",
      "Mean squared error:  19.350618490599125\n",
      "Mean absolute error:  3.6243028012533034\n",
      "R2 score:  0.7226031812031168\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Ahora podemos utilizar KerasRegressor para crear el modelo y ajustarlo a los datos\n",
    "mlp_keras = KerasRegressor(model=mlp, epochs=100, batch_size=5, verbose=1)\n",
    "mlp_keras.get_params()\n",
    "\n",
    "mlp_keras.fit(X,y) # vamos a entrenar usando CPU. En asignaturas posteriores veremos como entrenar usando GPU\n",
    "\n",
    "y_pred = mlp_keras.predict(X)\n",
    "\n",
    "print(\"Mean squared error: \", mean_squared_error(y, y_pred))\n",
    "print(\"Mean absolute error: \", mean_absolute_error(y, y_pred))\n",
    "print(\"R2 score: \", r2_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consideraciones generales\n",
    "\n",
    "Dese cuenta que no hemos aplicado ningún tipo de validación en los modelos. Estamos ajustando y evaluando el rendimiento en el conjunto completo, lo que no es nada recomendable. Queda en manos del estudiante aplicar los conocimientos de particionamiento y validación a los diferentes modelos aquí mostrados.\n",
    "\n",
    "De igual forma, no se ha realizado normalización en la mayoría de casos, lo que es muy recomendable (sobre todo trabajando con SGD). En la sesión de preprocesamiento se tratará con mayor profundidad, pero es necesario dejar constancia de este hecho.\n",
    "\n",
    "Finalmente, queremos indicar al estudiante que el ajuste de parámetros manual no es lo más óptimo hoy día. Más adelante estudiaremos como ajustar los parámetros de forma automatizada."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
