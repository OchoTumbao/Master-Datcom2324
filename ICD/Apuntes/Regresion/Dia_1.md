# Regresión y aprendizaje estadístico

Buscate An Introduction to Statistical Learning with Applications in R

- Que es el aprendizaje estadistico
  - El aprendizaje estadistico se basa en la estimación de una función de forma que a partir de una serie de observaciones de un cnjunto de datos donde existe una relación entre las observaciones. De modo que $Y_i = f(X_i)+\epsilon_i$, donde epsilon es un valor de error con media 0. Por ejemplo en un caso con un unico regresor seria obtener a partir de un conjunto de valores de una variable X la función que mejor estima los valores de Y. La dificultad de estimar f dependera de la desviacion estandar de los datos. Pero puede pasar que tenga mas de un regresor, por tanto estaria haciendo regresión lineal multiple.
- Porque queremos estimar una funcion
  - La razón principal es un uso predictivo, que cuando me llegue el conjunto de datos poder hacer predicción o poder hacer "inferencia" se llama así pero se refiere a inferir conocimientos, entender cual es la relación en los datos, que información y que conclusiones podemos sacar. Cuando queremos hacer un uso predictivo simplemente queremos sacar la respuesta, pero cuando queremos hacer inferencia lo que queremos sacar es conclusiones sobre que predictores afectan a la respuesta, si la relación es positiva o negativa o si la relación es una linear simple o es más compleja entre otras cosas a tener en cuenta
  - Como estimamos una función
    - Asume un conjunto de datos de entrenamiento, El plan es utilizar estos metodos de aprendizaje estadistico. Hay dos tipos de metodos, los parametricos y los no parametricos
      - En los metodos parametricos fijamos de antemano el tipo de modelo que vamos a tener y aprender despues una serie de parametros, por ejemplo un modelo lineal. Hay modelos más complejos que nos aportan flexibilidad. Esto los hace más realista, 
      - En las tecnicas no parametricas no se asume nada. No decidimos la estructura del modelo, esto hace que sean más precisos porque permiten más libertad a la hora de ajustarse a los datos. Lo malo, hace falta una gran cantidad de ejemplos o unos datos con muy poca desviación estandar. Estos siempre van a clavarla 
  - Equilibrio entre precisión e interpretabilidad
    - Jode macho si puedes ir al modelo más complejo y lo va a clavar, para que te molestas con los simples? Para la interpretabilidad. En modelos muy complejos la parte de inferencia es terrible, porque va a depender de tanta cosa que no vas a poder sacar ninguna conclusión clara. Por otro lado, aunque te la pele la interpretabilidad. Es más dificil obtener un modelo complejo bien ajustado, y si permites demasiados grados de libertad puedes llegar a un modelo sobreajustado que no funcione bien. La clave es buscar un equilibrio entre la complejidad y la precisión. En la realidad no hace falta matar moscas a cañonazos,
  - Supervisado vs unsupervised
    - Aprendizaje supervisado es cuando para mi conjunto de datos tengo los valores X y unas etiquetas de los valores que queremos predecir
    - Aprendizaje no supervisado es cuando no tengo esas etiquetas. Utilizamos la X para averiguar cual seria la Y, Usualmente tratando de dividir los datos en grupos. Esto es tipico de clasificación pero en regresión podemos hacer clustering para dividir los datos en grupos y montar sobre cada grupo un modelo de regresión
  - Regresión vs clasificacion
    - Regresión trata de estimar una variable continua, o con suficiente cantidad de casuistica como para considerarla continua, si quiero estimar Edades la variable no es continua, pero no voy a tener 99 grupos adivinando edades. Así que se trata como una regresión.  Mentras que en caso de la clasificación la variable es categorica.
    - Para lidiar con estos problemas, lo que tu quieras, por ejemplo random forest es una locura para clasificación y para regresión, pero vaya

# Regresión

  Ya tienes tu modelo, ahora como chotas lo mido, cual es la calidad del ajuste?, comprometemos el equilibrio sesgo varianza?, como esta funcionando las cosas?
  Suponte que estamos en clasificación, ahí la medida de acierto es facil, la cantidad de aciertos correctos. Pero en regresión no hay un valor de acietrto o fallo directo. Lo que se hace es calcular la diferencia entre el valor estimado y el real, se eleva al cuadrado, se sumaa para todos los errores y se divid entre el numero de ejemplos. Esto es lo que se conoce como error cuadratico medio. La idea es que si se me pira un dat de madre el error se me dispare. Problema, si yo diseño el modelo para ajustarse a los datos de entrenamiento, al punto en el que los clave eso no suele representar lo que es el mundo real. Para probar el modelo se suele utilizar "datos de test". La capacidad de rendir bien en datos de tes se llama capacidad de generalización.  En resumen lo que pasa es que no hay una solución magica y depende del problema, hay porblemas que dandole caña el train mejora pero el tesst se va a la mirda, otros dondeto yo le meto complejidad y siempre mejora y otro donde mejora hasta cierto punto y luego empeora. 

  En la realidad hay dos fuerzasque compiten, el seso y la varianza.El sesgo eslo que se produce cuando subestimo un problema y le doy un modelo demasiado sencillo, cuanto más simple el modelo mássesgo. La varianza es lo mucho que cambia tu f si tuviera un dataset diferente. 

# El modelo de regresión Lineal

Es un enfoque sencillo y util que asume que la dependencia entre Y e X es lineal. Ni una función en tu vida va a ser lineal, pero aunque sea super simple es una cosa muy util. Por eso se estudia. Nos permite estudiar si hay relaciones entre variables. Ver como de fuerte es la relación entre X e Y, ver que regresores aportan mas información.

E modelolineal simple consiste en aprender una función lineal para un unico regresor X que tiene la siguiente forma $Y = {\beta}_0 + {\beta}_1X + \epsilon$ donde las betas son constantess que representan la intercepción y la pendiente. Dado dos valores de beta estimados podemos calcular un valor estimado de y para cualquie valor del regresor X.

Para hacerlo podemos calcular la suma residual de los errores cuadrados como la suma de todas las diferencias entre la variable estimada por mi regresor y el valor real. La idea es plantear una ecuación en función de B0 y B1 que nos calcule el error para un par de betas concretos y luego despues minimizar esa ecuación buscando los valores de beta 1 y beta 0 donde minimizamos el error. A partir de ese calculo de esos betas podemos conocer como de preciso son los coeficientes. Calculando el valor estandar de error sobre cada uno de ellos. Eso me permite calcular un intervalo de confianza para cada coeficiente. Eso que quiere decir, que de todas las posibles lineas que podria obtener para esa regresión esta asegurado al 95% de confianza que el coeficiente me va a caer en ese intervalo. Y con eso para responder si hay una relación real entre el regresor y la variable podemos utilizar nuestra arma secreta, un test de hipotesis. Donde planteamos una hipotesis nula que diga que no hay relación entre la variable y el regresor. tenemos un intervalo de confianza, es muy facil ver que si el 0 no esta dentro de ese intervalo de confianza probar que la hipotesis nula no se cumple al 95. Pero vaya, loque se hace es calcular un estadistico T beta1-0/SE(B1) que se ajusta a una distriución t con n-2 grados de libertad  y con ese estadistico y un software estadistico se calcula un p-value y como siempre si esta muy cercano a 0 la probabilidad de linealidad es muy baja.

Tambien podemos calcular el error global del modelo. Pero vaya, error cuadratico medio o el error residual estandar, que haciendo tres cosas cambias de uno a otro. Con ese error puedo calcular un estadistico R² que me calcula enun valor entre 0 y 1 cuanto explica mi linea de la correlación, de hecho ese estadistico R² es equivalente al cuadrado de la correlación entre X e Y

## Regresión lineal multiple

Ahi nuestro modelo parametrico tiene mas de un regresor, el funcionamiento por ese lado es el mismo, pero hay que tener cosas en cuenta. Lo primero es que los predictores que este utilizando no tengan correlaciones fuertes. Y si tengo muchas correlaciones fuertes lo que puede pasar es que los p-valores que calculamos antes se vayan a la mierda. Y por otra parte hacer interpretaciones se complica. Pero aún así no podemos establecer causalidades. 